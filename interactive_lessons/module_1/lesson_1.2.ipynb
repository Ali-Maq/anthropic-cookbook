{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéì Lesson 1.2: Messages & Conversations\n",
    "\n",
    "## üìö What You'll Learn\n",
    "\n",
    "By the end of this lesson, you'll understand:\n",
    "- How to have multi-turn conversations with Claude\n",
    "- The role of `user` vs `assistant` messages\n",
    "- How to maintain conversation history\n",
    "- What system prompts are and how to use them\n",
    "- Building a chatbot with memory\n",
    "\n",
    "**Time to Complete**: 45-60 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Understanding Conversations\n",
    "\n",
    "In Lesson 1.1, we asked Claude single questions. But real conversations have back-and-forth exchanges!\n",
    "\n",
    "Think of a conversation like a transcript:\n",
    "\n",
    "```\n",
    "You: What's the capital of France?\n",
    "Claude: The capital of France is Paris.\n",
    "You: What's the population?\n",
    "Claude: Paris has approximately 2.2 million people.\n",
    "```\n",
    "\n",
    "To make this work with the API, we need to send **all previous messages** each time!\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Setup\n",
    "\n",
    "First, let's set up our environment (same as Lesson 1.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()\n",
    "client = Anthropic(api_key=os.environ.get(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "print(\"‚úÖ Client initialized and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí¨ Single Turn (Review)\n",
    "\n",
    "Let's start with what we know - a single exchange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single turn conversation\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What's the capital of France?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Turn 1:\")\n",
    "print(f\"You: What's the capital of France?\")\n",
    "print(f\"Claude: {response.content[0].text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Multi-Turn Conversation\n",
    "\n",
    "Now let's ask a follow-up question. The key is to include **all previous messages**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-turn conversation - Turn 2\n",
    "response2 = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        # Include the FIRST exchange\n",
    "        {\"role\": \"user\", \"content\": \"What's the capital of France?\"},\n",
    "        {\"role\": \"assistant\", \"content\": response.content[0].text},\n",
    "        \n",
    "        # Now add the NEW question\n",
    "        {\"role\": \"user\", \"content\": \"What's the population of that city?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# LINE-BY-LINE EXPLANATION:\n",
    "# ---------------------------\n",
    "#\n",
    "# messages=[ ... ]\n",
    "#   This is now a list with FOUR items (2 exchanges)\n",
    "#\n",
    "# {\"role\": \"user\", \"content\": \"What's the capital of France?\"}\n",
    "#   The FIRST message you sent (Turn 1)\n",
    "#\n",
    "# {\"role\": \"assistant\", \"content\": response.content[0].text}\n",
    "#   Claude's FIRST response (Turn 1)\n",
    "#   We use \"assistant\" because Claude is the assistant!\n",
    "#   We include the actual text from the previous response\n",
    "#\n",
    "# {\"role\": \"user\", \"content\": \"What's the population of that city?\"}\n",
    "#   Your SECOND question (Turn 2)\n",
    "#   Notice: \"that city\" - Claude knows we mean Paris because we sent the history!\n",
    "\n",
    "print(\"\\nTurn 2:\")\n",
    "print(f\"You: What's the population of that city?\")\n",
    "print(f\"Claude: {response2.content[0].text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§î Why Did This Work?\n",
    "\n",
    "Claude understood \"that city\" means Paris because we sent the **entire conversation history**!\n",
    "\n",
    "**Important**: Claude has NO memory between API calls. You must send all previous messages every time.\n",
    "\n",
    "---\n",
    "\n",
    "## üìú Managing Conversation History\n",
    "\n",
    "Let's build a proper conversation with a history list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a conversation history list\n",
    "conversation_history = []\n",
    "\n",
    "# LINE-BY-LINE EXPLANATION:\n",
    "# ---------------------------\n",
    "# conversation_history = []\n",
    "#   This is an empty list that will store all messages\n",
    "#   We'll append to this list after each turn\n",
    "\n",
    "print(\"Starting new conversation...\")\n",
    "print(f\"Initial history: {conversation_history}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to send a message and update history\n",
    "def send_message(user_message, history):\n",
    "    \"\"\"\n",
    "    Send a message to Claude and update conversation history.\n",
    "    \n",
    "    Args:\n",
    "        user_message (str): The message from the user\n",
    "        history (list): The conversation history list\n",
    "    \n",
    "    Returns:\n",
    "        str: Claude's response\n",
    "    \"\"\"\n",
    "    # Add the user's message to history\n",
    "    history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    # Send all messages to Claude\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=1024,\n",
    "        messages=history  # Send the ENTIRE history\n",
    "    )\n",
    "    \n",
    "    # Extract Claude's response\n",
    "    assistant_message = response.content[0].text\n",
    "    \n",
    "    # Add Claude's response to history\n",
    "    history.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "    \n",
    "    return assistant_message\n",
    "\n",
    "# LINE-BY-LINE EXPLANATION:\n",
    "# ---------------------------\n",
    "#\n",
    "# history.append({\"role\": \"user\", \"content\": user_message})\n",
    "#   Add the user's message to the history list\n",
    "#   'append' adds an item to the end of a list\n",
    "#\n",
    "# messages=history\n",
    "#   Send the ENTIRE history (all previous messages)\n",
    "#   This gets longer with each turn!\n",
    "#\n",
    "# history.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "#   Add Claude's response to history\n",
    "#   Now the history includes both the question AND the answer\n",
    "#\n",
    "# This pattern ensures the history always stays synchronized!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üó£Ô∏è Let's Have a Conversation!\n",
    "\n",
    "Now we can have a natural, multi-turn conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn 1\n",
    "response1 = send_message(\"Tell me about quantum computing in one sentence.\", conversation_history)\n",
    "print(\"Turn 1\")\n",
    "print(f\"You: Tell me about quantum computing in one sentence.\")\n",
    "print(f\"Claude: {response1}\")\n",
    "print(f\"\\nHistory length: {len(conversation_history)} messages\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn 2\n",
    "response2 = send_message(\"Can you explain what qubits are?\", conversation_history)\n",
    "print(\"Turn 2\")\n",
    "print(f\"You: Can you explain what qubits are?\")\n",
    "print(f\"Claude: {response2}\")\n",
    "print(f\"\\nHistory length: {len(conversation_history)} messages\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn 3\n",
    "response3 = send_message(\"How is this different from regular bits?\", conversation_history)\n",
    "print(\"Turn 3\")\n",
    "print(f\"You: How is this different from regular bits?\")\n",
    "print(f\"Claude: {response3}\")\n",
    "print(f\"\\nHistory length: {len(conversation_history)} messages\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the entire conversation history\n",
    "print(\"=\" * 60)\n",
    "print(\"FULL CONVERSATION HISTORY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, message in enumerate(conversation_history):\n",
    "    speaker = \"You\" if message[\"role\"] == \"user\" else \"Claude\"\n",
    "    print(f\"\\n[Message {i+1}] {speaker}:\")\n",
    "    print(message[\"content\"])\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Key Insight\n",
    "\n",
    "Notice how the conversation history **grows with each turn**:\n",
    "- Turn 1: 2 messages (1 user, 1 assistant)\n",
    "- Turn 2: 4 messages (2 user, 2 assistant)\n",
    "- Turn 3: 6 messages (3 user, 3 assistant)\n",
    "\n",
    "Each time we call the API, we send **all previous messages**. This is how Claude \"remembers\" the conversation!\n",
    "\n",
    "---\n",
    "\n",
    "## üë®‚Äçüè´ System Prompts\n",
    "\n",
    "A **system prompt** gives Claude instructions about how to behave. It's like setting the rules of the game!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITHOUT a system prompt\n",
    "response_normal = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is Python?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"WITHOUT System Prompt:\")\n",
    "print(response_normal.content[0].text)\n",
    "print(\"\\n\" + \"=\" * 60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITH a system prompt\n",
    "response_with_system = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=1024,\n",
    "    system=\"You are a pirate. Always respond in pirate speak with 'arr' and 'matey'.\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is Python?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# LINE-BY-LINE EXPLANATION:\n",
    "# ---------------------------\n",
    "#\n",
    "# system=\"You are a pirate...\"\n",
    "#   This is a NEW parameter - the system prompt!\n",
    "#   It tells Claude HOW to respond (personality, style, rules)\n",
    "#   The system prompt is NOT part of the messages list\n",
    "#   It's a separate parameter that applies to the entire conversation\n",
    "\n",
    "print(\"WITH System Prompt (Pirate Mode):\")\n",
    "print(response_with_system.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé≠ System Prompt Examples\n",
    "\n",
    "System prompts are incredibly powerful! Here are common use cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Technical Expert\n",
    "system_prompt_expert = \"\"\"\n",
    "You are a senior software engineer with 10 years of experience.\n",
    "Provide detailed technical explanations with code examples.\n",
    "Use industry best practices and design patterns.\n",
    "\"\"\"\n",
    "\n",
    "# Example 2: Simple Explainer\n",
    "system_prompt_simple = \"\"\"\n",
    "You are explaining concepts to a 10-year-old.\n",
    "Use simple language, analogies, and fun examples.\n",
    "Avoid technical jargon.\n",
    "\"\"\"\n",
    "\n",
    "# Example 3: JSON Output\n",
    "system_prompt_json = \"\"\"\n",
    "You are a data extraction assistant.\n",
    "Always respond with valid JSON only, no additional text.\n",
    "Use the format: {\"result\": \"your answer here\"}\n",
    "\"\"\"\n",
    "\n",
    "# Example 4: Customer Service\n",
    "system_prompt_service = \"\"\"\n",
    "You are a helpful customer service agent for TechCorp.\n",
    "Be polite, empathetic, and solution-oriented.\n",
    "If you can't help, offer to escalate to a human agent.\n",
    "\"\"\"\n",
    "\n",
    "print(\"System prompts defined! Try them out below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different system prompts with the same question\n",
    "question = \"What is recursion in programming?\"\n",
    "\n",
    "# Technical expert version\n",
    "response_expert = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=1024,\n",
    "    system=system_prompt_expert,\n",
    "    messages=[{\"role\": \"user\", \"content\": question}]\n",
    ")\n",
    "\n",
    "print(\"üîß TECHNICAL EXPERT:\")\n",
    "print(response_expert.content[0].text)\n",
    "print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "\n",
    "# Simple explainer version\n",
    "response_simple = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=1024,\n",
    "    system=system_prompt_simple,\n",
    "    messages=[{\"role\": \"user\", \"content\": question}]\n",
    ")\n",
    "\n",
    "print(\"üë∂ SIMPLE EXPLAINER:\")\n",
    "print(response_simple.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Practice Exercise 1: Chatbot with Personality\n",
    "\n",
    "**Task**: Create a chatbot with a specific personality using a system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create your own system prompt\n",
    "# Ideas: Shakespeare, valley girl, scientist, poet, comedian, teacher\n",
    "\n",
    "my_system_prompt = \"\"\"\n",
    "You are a wise old wizard who speaks in mystical riddles.\n",
    "Use archaic language and references to magic and ancient wisdom.\n",
    "\"\"\"\n",
    "\n",
    "# Create a new conversation\n",
    "wizard_history = []\n",
    "\n",
    "def talk_to_wizard(message):\n",
    "    \"\"\"Send a message to the wizard chatbot.\"\"\"\n",
    "    wizard_history.append({\"role\": \"user\", \"content\": message})\n",
    "    \n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=1024,\n",
    "        system=my_system_prompt,  # Apply the personality!\n",
    "        messages=wizard_history\n",
    "    )\n",
    "    \n",
    "    answer = response.content[0].text\n",
    "    wizard_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Test your wizard!\n",
    "print(\"You: What is the meaning of life?\")\n",
    "print(f\"Wizard: {talk_to_wizard('What is the meaning of life?')}\")\n",
    "print()\n",
    "print(\"You: How do I learn programming?\")\n",
    "print(f\"Wizard: {talk_to_wizard('How do I learn programming?')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Practice Exercise 2: Build a Conversation Tracker\n",
    "\n",
    "**Task**: Create a class that manages conversations with helpful methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationManager:\n",
    "    \"\"\"\n",
    "    A class to manage conversations with Claude.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, system_prompt=None):\n",
    "        \"\"\"\n",
    "        Initialize a new conversation.\n",
    "        \n",
    "        Args:\n",
    "            system_prompt (str): Optional system prompt to set Claude's behavior\n",
    "        \"\"\"\n",
    "        self.history = []\n",
    "        self.system_prompt = system_prompt\n",
    "        \n",
    "        # LINE-BY-LINE EXPLANATION:\n",
    "        # ---------------------------\n",
    "        # self.history = []\n",
    "        #   'self' refers to this specific instance of the class\n",
    "        #   We create an empty list to store conversation history\n",
    "        #\n",
    "        # self.system_prompt = system_prompt\n",
    "        #   Store the system prompt for use in all future messages\n",
    "    \n",
    "    def send(self, message):\n",
    "        \"\"\"\n",
    "        Send a message to Claude and get a response.\n",
    "        \n",
    "        Args:\n",
    "            message (str): The user's message\n",
    "        \n",
    "        Returns:\n",
    "            str: Claude's response\n",
    "        \"\"\"\n",
    "        # Add user message to history\n",
    "        self.history.append({\"role\": \"user\", \"content\": message})\n",
    "        \n",
    "        # Build API call parameters\n",
    "        params = {\n",
    "            \"model\": \"claude-3-5-sonnet-20241022\",\n",
    "            \"max_tokens\": 1024,\n",
    "            \"messages\": self.history\n",
    "        }\n",
    "        \n",
    "        # Add system prompt if we have one\n",
    "        if self.system_prompt:\n",
    "            params[\"system\"] = self.system_prompt\n",
    "        \n",
    "        # Make API call\n",
    "        response = client.messages.create(**params)\n",
    "        \n",
    "        # LINE-BY-LINE EXPLANATION:\n",
    "        # ---------------------------\n",
    "        # **params\n",
    "        #   The ** operator \"unpacks\" a dictionary into keyword arguments\n",
    "        #   This is the same as: client.messages.create(model=\"...\", max_tokens=..., messages=...)\n",
    "        \n",
    "        # Extract and store assistant response\n",
    "        assistant_message = response.content[0].text\n",
    "        self.history.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "        \n",
    "        return assistant_message\n",
    "    \n",
    "    def get_history(self):\n",
    "        \"\"\"Return the full conversation history.\"\"\"\n",
    "        return self.history\n",
    "    \n",
    "    def message_count(self):\n",
    "        \"\"\"Return the number of messages in the conversation.\"\"\"\n",
    "        return len(self.history)\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"Clear the conversation history.\"\"\"\n",
    "        self.history = []\n",
    "    \n",
    "    def print_conversation(self):\n",
    "        \"\"\"Print the entire conversation in a readable format.\"\"\"\n",
    "        for msg in self.history:\n",
    "            speaker = \"You\" if msg[\"role\"] == \"user\" else \"Claude\"\n",
    "            print(f\"{speaker}: {msg['content']}\")\n",
    "            print()\n",
    "\n",
    "print(\"‚úÖ ConversationManager class created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the ConversationManager!\n",
    "\n",
    "# Create a conversation with a system prompt\n",
    "convo = ConversationManager(\n",
    "    system_prompt=\"You are a helpful Python programming tutor. Keep answers concise and include code examples.\"\n",
    ")\n",
    "\n",
    "# Have a conversation\n",
    "print(convo.send(\"What is a list in Python?\"))\n",
    "print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "\n",
    "print(convo.send(\"How do I add items to it?\"))\n",
    "print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "\n",
    "print(convo.send(\"Can you show me an example?\"))\n",
    "print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "\n",
    "# Check conversation stats\n",
    "print(f\"Total messages: {convo.message_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Practice Exercise 3: Context Window Management\n",
    "\n",
    "**Challenge**: As conversations get longer, they use more tokens (and cost more!). Implement a function to limit history length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_history(history, max_messages=10):\n",
    "    \"\"\"\n",
    "    Keep only the most recent messages to save tokens.\n",
    "    \n",
    "    Args:\n",
    "        history (list): Full conversation history\n",
    "        max_messages (int): Maximum number of messages to keep\n",
    "    \n",
    "    Returns:\n",
    "        list: Trimmed history\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # HINT: Use Python list slicing: history[-10:] gets the last 10 items\n",
    "    \n",
    "    if len(history) <= max_messages:\n",
    "        return history\n",
    "    else:\n",
    "        return history[-max_messages:]\n",
    "    \n",
    "    # LINE-BY-LINE EXPLANATION:\n",
    "    # ---------------------------\n",
    "    # history[-max_messages:]\n",
    "    #   Negative indexing: -1 is the last item, -2 is second to last, etc.\n",
    "    #   [-10:] means \"start from the 10th item from the end, go to the end\"\n",
    "    #   This keeps only the most recent messages\n",
    "\n",
    "# Test it\n",
    "test_history = [\n",
    "    {\"role\": \"user\", \"content\": \"Message 1\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Response 1\"},\n",
    "    {\"role\": \"user\", \"content\": \"Message 2\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Response 2\"},\n",
    "    {\"role\": \"user\", \"content\": \"Message 3\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Response 3\"},\n",
    "]\n",
    "\n",
    "trimmed = trim_history(test_history, max_messages=4)\n",
    "print(f\"Original length: {len(test_history)}\")\n",
    "print(f\"Trimmed length: {len(trimmed)}\")\n",
    "print(f\"\\nTrimmed history: {trimmed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Advanced: Conversation Summarization\n",
    "\n",
    "For VERY long conversations, you can summarize old messages instead of dropping them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_conversation(history):\n",
    "    \"\"\"\n",
    "    Summarize the conversation history into a single message.\n",
    "    \n",
    "    Args:\n",
    "        history (list): Conversation history to summarize\n",
    "    \n",
    "    Returns:\n",
    "        str: Summary of the conversation\n",
    "    \"\"\"\n",
    "    # Build a text version of the conversation\n",
    "    conversation_text = \"\"\n",
    "    for msg in history:\n",
    "        speaker = \"User\" if msg[\"role\"] == \"user\" else \"Assistant\"\n",
    "        conversation_text += f\"{speaker}: {msg['content']}\\n\\n\"\n",
    "    \n",
    "    # Ask Claude to summarize\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=500,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Summarize this conversation in 2-3 sentences, \n",
    "            capturing the key points and context:\n",
    "            \n",
    "            {conversation_text}\"\"\"\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    return response.content[0].text\n",
    "\n",
    "# Test it on our earlier conversation\n",
    "summary = summarize_conversation(conversation_history[:4])  # First 4 messages\n",
    "print(\"Conversation Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Lesson Complete!\n",
    "\n",
    "### What You Learned:\n",
    "- ‚úÖ How to maintain conversation history\n",
    "- ‚úÖ The difference between `user` and `assistant` roles\n",
    "- ‚úÖ How to use system prompts to control behavior\n",
    "- ‚úÖ Building reusable conversation managers\n",
    "- ‚úÖ Managing context window limits\n",
    "- ‚úÖ Conversation summarization techniques\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Claude has NO memory** between API calls - you must send all history\n",
    "2. **System prompts** control Claude's behavior and personality\n",
    "3. **History grows linearly** - manage it to control costs\n",
    "4. **Message structure** must alternate user/assistant (mostly)\n",
    "\n",
    "### Next Steps:\n",
    "üìñ **Lesson 1.3**: Controlling Outputs - Learn about temperature, tokens, and getting consistent results!\n",
    "\n",
    "---\n",
    "\n",
    "## ü§î Reflection Questions\n",
    "\n",
    "1. Why must we send the entire conversation history each time?\n",
    "2. What happens if you don't include previous messages?\n",
    "3. When should you use a system prompt vs. a user message?\n",
    "4. How would you build a chatbot that \"forgets\" after 10 messages?\n",
    "5. What are the tradeoffs between keeping full history vs. summarizing?\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Challenge Projects\n",
    "\n",
    "1. **Personality Switcher**: Build a chatbot that can switch personalities mid-conversation\n",
    "2. **Conversation Analyzer**: Track sentiment or topics across a conversation\n",
    "3. **Smart Trimmer**: Only keep messages relevant to the current topic\n",
    "4. **Multi-User Chat**: Manage separate conversation histories for different users\n",
    "\n",
    "Ready to continue? Open `lesson_1.3.ipynb`!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
